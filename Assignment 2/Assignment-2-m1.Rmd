---
title: "Stan model implementation"
author: "Astrid NÃ¸rgaard Fonager"
date: "2023-03-01"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(pacman)

pacman::p_load(tidyverse,
        here,
        posterior,
        cmdstanr,
        brms, tidybayes, future, purrr, furrr, prettydoc)
```

# FUNCTIONS

```{r agent functions}

# Random bot
random_agent <- function(bias = 0.7) {
  choice <- rbinom(1,1, bias)
  return(choice)
}

# Win-shift-lose-stay agent
win_shift_agent <- function(prev_choice, feedback, bias_lose, bias_win) {
  if (feedback == 0) { #lose stay
    if(prev_choice == 0) { 
      choice = rbinom(1, 1, (1-bias_lose))}
    if(prev_choice == 1) { 
      choice = rbinom(1, 1, bias_lose)}
      }
  else if (feedback == 1) { #win shift
    if(prev_choice == 0) { 
      choice = rbinom(1, 1, bias_win)}
    if(prev_choice == 1) { 
      choice = rbinom(1, 1, (1-bias_win))}
  }
  return(choice)  
}
```


```{r simulation function RA}

sim_vs_random <- function(agents, trials, bias_lose, bias_win){
  
  feedback <- array(NA, c(agents, trials))
  performance_df <- data_frame()
  
  for (agent in 1:agents){
    self <- rep(NA, trials)
    bot <- rep(NA, trials)
  
    self[1] <- random_agent(0.5)
    
    for(trial in seq(trials)) {
      bot[trial] <- random_agent()
    }
    
    for (trial in 2:trials){
      if(self[trial-1] == bot[trial-1]) {
        feedback[agent, trial] = 1
      } 
      else {
        feedback[agent, trial] = 0
      }
      self[trial] <- win_shift_agent(prev_choice = self[trial-1], 
                                      feedback = feedback[agent, trial], 
                                      bias_lose = bias_lose, 
                                      bias_win = bias_win)
    }
    
    df_temp <- tibble(agent = agent, self, bot, trial = seq(trials), 
                      feedback = as.numeric(self==bot)) %>% 
      mutate(cumulative_self = cumsum(feedback)/seq_along(feedback),
             cumulative_bot = cumsum(1-feedback)/seq_along(feedback)) 
    
    performance_df <- rbind(performance_df, df_temp)
    
  }
  
  return(performance_df)
}
```


```{r simulation and fitting function}

sim_d_and_fit <- function(seed, trials, bias_win, bias_lose) {
  for (t in seq(trials)) {
    temp <-  sim_vs_random(agents = 1,
                           trials = trials, 
                           bias_lose = bias_lose,
                           bias_win = bias_win)
  }
  
  data <-  list(
    t = trials,
    choice = lag(temp$self, 1),
    self = temp$self,
    other = temp$bot
  )
  
  data$choice[1] <- 0

  samples <- model$sample(
    data = data,
    seed = seed,
    chains = 1,
    parallel_chains = 1,
    threads_per_chain = 1,
    iter_warmup = 1000,
    iter_sampling = 2000,
    refresh = 0,
    max_treedepth = 20,
    adapt_delta = 0.99,
  )

  draws_df <- as_draws_df(samples$draws())
  temp <- tibble(bias_winEst = draws_df$bias_win, 
                 bias_loseEst = draws_df$bias_lose, 
                 bias_winTrue = bias_win, 
                 bias_loseTrue = bias_lose)
  
  return(temp)
}

```

# FITTING THE MODEL

```{r import model}
setwd("/Users/astridnorgaardfonager/Documents/CogSci/8th semester/ACM/Assignments/A2/")

## Specify where the model is
file <- file.path("stan/model1.stan")
model <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1")) 


```


```{r test fitting}
test <- sim_d_and_fit(seed = 1000, trials = 100, bias_win = 0.7, bias_lose = 0.9)
```

