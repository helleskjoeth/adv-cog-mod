---
title: "Assignment-2"
author: "Helle"
date: "2023-03-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(tidyverse,
        here,
        posterior,
        cmdstanr,
        brms, tidybayes)

```



Making our agents   
```{r making our win shift agent}

win_shift_agent <- function(prev_choice, feedback, bias_lose, bias_win) {
  if (feedback == 0) { #lose stay
    if(prev_choice == 0) { 
      choice = rbinom(1, 1, (1-bias_lose))}
    if(prev_choice == 1) { 
      choice = rbinom(1, 1, bias_lose)}
      }
  else if (feedback == 1) { #win shift
    if(prev_choice == 0) { 
      choice = rbinom(1, 1, bias_win)}
    if(prev_choice == 1) { 
      choice = rbinom(1, 1, (1-bias_win))}
  }
  return(choice)  }


random_agent <- function(bias) {
  choice <- rbinom(1,1, bias)
  return(choice)
}

```


```{r simulation of data function - random bot}
sim_vs_random <- function(agents, trials, bias_lose, bias_win){
  
  feedback <- array(NA, c(agents, trials))
  performance_df <- data_frame()
  
  for (agent in 1:agents){
    self <- rep(NA, trials)
    bot <- rep(NA, trials)
  
    self[1] <- random_agent(0.5)
    
    for(trial in seq(trials)) {
      bot[trial] <- random_agent(bot_bias)
    }
    
    for (trial in 2:trials){
      if(self[trial-1] == bot[trial-1]) {
        feedback[agent, trial] = 1
      } 
      else {
        feedback[agent, trial] = 0
      }
      self[trial] <- win_shift_agent(prev_choice = self[trial-1], 
                                      feedback = feedback[agent, trial], 
                                      bias_lose = bias_lose, 
                                      bias_win = bias_win)
    }
    
    df_temp <- tibble(agent = agent, self, bot, trial = seq(trials), 
                      feedback = as.numeric(self==bot)) %>% 
      mutate(cumulative_self = cumsum(feedback)/seq_along(feedback),
             cumulative_bot = cumsum(1-feedback)/seq_along(feedback)) 
    
    performance_df <- rbind(performance_df, df_temp)
    
  }
  
  return(performance_df)
}
```




```{r sim_d_and_fit function}
sim_d_and_fit <- function(seed, agents, trials, bias_lose, bias_win) {
  for (t in seq(trials)) { 
    temp <- sim_vs_random(agents = agents, 
                          trials = trials, 
                          bias_lose = bias_lose,
                          bias_win = bias_lose)
}
data <- list(
  t = trials,
  choice = temp$self,
  feedback = temp$feedback 
)

samples <- mod$sample(
  data = data,
  seed = 1000,
  chains = 1, 
  parallel_chains = 1, 
  threads_per_chain = 1, 
  iter_warmup = 1000,
  iter_sampling = 2000,
  refresh = 0,
  max_treedepth = 20,
  adapt_delta = 0.99
)

draws_df <- as_draws_df(samples$draws())
temp <- tibble(biasEst= draws_df$bias_posterior, bias_lose_True = bias_lose, bias_win_True = bias_win)


return(draws_df)

}

```

```{r}
setwd("C:/Users/helle/OneDrive - Aarhus Universitet/AU/8th semester/Adv. Cognitive Modelling/adv-cog-mod")

## Specify where the model is
file <- file.path("C:/Users/helle/OneDrive - Aarhus Universitet/AU/8th semester/Adv. Cognitive Modelling/adv-cog-mod/ass-2.stan")
mod <- cmdstan_model(file, 
                     # this specifies we can parallelize the gradient estimations on multiple cores
                     cpp_options = list(stan_threads = TRUE), 
                     # this is a trick to make it faster
                     stanc_options = list("O1")) 

```

```{r}
test <- sim_d_and_fit(seed = 1000, agents = 1, trials = 10 , bias_lose = 0.9, bias_win = 0.7)
```

