---
title: "assignment 2"
author: "Sigrid Agersnap Bom Nielsen"
date: "2023-03-07"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(pacman)

pacman::p_load(tidyverse,
        here,
        posterior,
        cmdstanr,
        brms, tidybayes, future, purrr, furrr)
```

# FUNCTIONS

```{r agent functions}

# Random bot
random_agent <- function(bias = 0.7) {
  choice <- rbinom(1,1, bias)
  return(choice)
}

# Win-shift-lose-stay agent
win_shift_agent <- function(prev_choice, feedback, bias_lose, bias_win) {
  if (feedback == 0) { #lose stay
    if(prev_choice == 0) { 
      choice = rbinom(1, 1, (1-bias_lose))}
    if(prev_choice == 1) { 
      choice = rbinom(1, 1, bias_lose)}
      }
  else if (feedback == 1) { #win shift
    if(prev_choice == 0) { 
      choice = rbinom(1, 1, bias_win)}
    if(prev_choice == 1) { 
      choice = rbinom(1, 1, (1-bias_win))}
  }
  return(choice)  
}
```


```{r simulation function RA}

sim_vs_random <- function(agents, trials, bias_lose, bias_win){
  
  feedback <- array(NA, c(agents, trials))
  performance_df <- data_frame()
  
  for (agent in 1:agents){
    self <- rep(NA, trials)
    bot <- rep(NA, trials)
  
    self[1] <- random_agent(0.5)
    
    for(trial in seq(trials)) {
      bot[trial] <- random_agent()
    }
    
    for (trial in 2:trials){
      if(self[trial-1] == bot[trial-1]) {
        feedback[agent, trial] = 1
      } 
      else {
        feedback[agent, trial] = 0
      }
      self[trial] <- win_shift_agent(prev_choice = self[trial-1], 
                                      feedback = feedback[agent, trial], 
                                      bias_lose = bias_lose, 
                                      bias_win = bias_win)
    }
    
    df_temp <- tibble(agent = agent, self, bot, trial = seq(trials), 
                      feedback = as.numeric(self==bot)) %>% 
      mutate(cumulative_self = cumsum(feedback)/seq_along(feedback),
             cumulative_bot = cumsum(1-feedback)/seq_along(feedback)) 
    
    performance_df <- rbind(performance_df, df_temp)
    
  }
  
  return(performance_df)
}
```


```{r simulation and fitting function}

sim_d_and_fit <- function(seed, trials, bias_win, bias_lose) {
  for (t in seq(trials)) {
    temp <-  sim_vs_random(agents = 1,
                           trials = trials, 
                           bias_lose = bias_lose,
                           bias_win = bias_win)
  }
  
  data <-  list(
    t = trials,
    choice = lag(temp$self, 1),
    self = temp$self,
    other = temp$bot
  )
  
  data$choice[1] <- 0

  samples <- model$sample(
    data = data,
    seed = seed,
    chains = 1,
    parallel_chains = 1,
    threads_per_chain = 1,
    iter_warmup = 1000,
    iter_sampling = 2000,
    refresh = 0,
    max_treedepth = 20,
    adapt_delta = 0.99,
  )

  draws_df <- as_draws_df(samples$draws())
  temp <- tibble(bias_winEst = draws_df$bias_win_posterior, 
                 bias_loseEst = draws_df$bias_lose_posterior, 
                 bias_winTrue = bias_win, 
                 bias_loseTrue = bias_lose)
  temp2 <- draws_df[104:115]
  
  df <- cbind(temp, temp2)
    
  
  return(df)
}

```

# FITTING THE MODEL

```{r import model}
## Specify where the model is
file <- file.path("model1.stan")
model <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1")) 


```


```{r test fitting}
test <- sim_d_and_fit(seed = 1000, trials = 100, bias_win = 0.7, bias_lose = 0.9)
```
# Parameter recovery

```{r}
pacman::p_load(tidyr, patchwork)
plan(multisession, workers = 4)

bias_win = seq(0,1, by = .1)
bias_lose = seq(0,1,by = .1)

d <- crossing(bias_win, bias_lose)

temp <- tibble(unique(d)) %>% 
  mutate(seed = 1000, trials = 120) # is seed what gives me 2000 estimated values pr combination of true values?? 

recovery_df <- future_pmap_dfr(temp, sim_d_and_fit, .options = furrr_options(seed = TRUE))
getwd()

write.csv(recovery_df, "recovery_df.csv", row.names = FALSE)
```


```{r}
p1 <- ggplot(recovery_df, aes(bias_winTrue, bias_winEst)) + 
  geom_point(alpha = 0.1) + 
  geom_smooth() +
  theme_classic() + 
  labs(title = "Bias_win") + 
  geom_abline(
    slope = 1, 
    intercept = 0,
    color = "red")
# + facet_wrap(.~bias_loseTrue) # not sure it makes sense to plot with a facetwrap 

p2 <- ggplot(recovery_df, aes(bias_loseTrue, bias_loseEst)) +
  geom_point(alpha = 0.1) + 
  geom_smooth() +
  theme_classic() + 
  labs(title = "Bias_lose") +
  geom_abline(
    slope = 1, 
    intercept = 0,
    color = "red")

p1 + p2
# looks weird, I suspect the scale of the estimated values needs to be fixed 
```





# plotting time!! win stay vs. random agent 
# posterior + priors 
```{r}
# bias win
ggplot(test) +
  geom_density(aes(bias_win_posterior), fill="blue", alpha=0.3) +
  geom_density(aes(bias_win_prior), fill="red", alpha=0.3) +
  xlab("Rate") + # Tendency to choose 1 ??
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = "Bias win")
# bias lose
ggplot(test) +
  geom_density(aes(bias_lose_posterior), fill="blue", alpha=0.3) +
  geom_density(aes(bias_lose_prior), fill="red", alpha=0.3) +
  xlab("Rate") +
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = "Bias lose")
```
Remember, win-shift!

```{r}
# prior predictions - when losing 
ggplot(test) +
  geom_histogram(aes(prior_preds_bias_lose_c0), color="darkblue", fill="blue", alpha=0.3) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = "Prior predicted next choice when the agent choses 0 and loses")
ggplot(test) + 
  geom_histogram(aes(prior_preds_bias_lose_c0), color="lightblue", fill="blue", alpha=0.3, bins=90) +
  geom_histogram(aes(posterior_preds_bias_lose_c0), color="darkblue", fill="blue", alpha=0.3, bins=90) +
  #geom_point(x = 0.7*100, y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Density") +
  theme_classic() + 
  labs(title = "Prior and posterior predicted choice when the agent choses 0 and loses")
```
So, the agent loses and has a stronger tendency to stay a their choice when losing. So the posterior distribution is pulled towards 0, which was the choice where the agent lost. 

```{r}
ggplot(test) +
  geom_histogram(aes(prior_preds_bias_lose_c1), color="darkblue", fill="blue", alpha=0.3) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = "Prior predicted next choice when the agent choses 1 and loses")
ggplot(test) + 
  geom_histogram(aes(prior_preds_bias_lose_c1), color="lightblue", fill="blue", alpha=0.3, bins=90) +
  geom_histogram(aes(posterior_preds_bias_lose_c1), color="darkblue", fill="blue", alpha=0.3, bins=90) +
  #geom_point(x = 0.9*100, y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Density") +
  theme_classic() + 
  labs(title = "Prior and posterior predicted choice when the agent choses 1 and loses")
```
But according to the above explanation this distribution should be pulled towards 1.... 

```{r}
# prior predictions - when winning
ggplot(test) +
  geom_histogram(aes(prior_preds_bias_win_c0), color="darkblue", fill="blue", alpha=0.3) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = "Prior predicted next choice when the agent choses 0 and wins")
ggplot(test) + 
  geom_histogram(aes(prior_preds_bias_win_c0), color="lightblue", fill="blue", alpha=0.3, bins=90) +
  geom_histogram(aes(posterior_preds_bias_win_c0), color="darkblue", fill="blue", alpha=0.3, bins=90) +
 # geom_point(x = 0.7*100, y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Density") +
  theme_classic() + 
  labs(title = "Prior and posterior predicted choice when the agent choses 0 and wins")
```


```{r}
ggplot(test) +
  geom_histogram(aes(prior_preds_bias_win_c1), color="darkblue", fill="blue", alpha=0.3) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic() +
  labs(title = "Prior predicted next choice when the agent choses 1 and wins")
ggplot(test) + 
  geom_histogram(aes(prior_preds_bias_win_c1), color="lightblue", fill="blue", alpha=0.3, bins=90) +
  geom_histogram(aes(posterior_preds_bias_win_c1), color="darkblue", fill="blue", alpha=0.3, bins=90) +
#  geom_point(x = 0.7*100, y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Density") +
  theme_classic() + 
  labs(title = "Prior and posterior predicted choice when the agent choses 1 and wins")
```
Priors looks good. 