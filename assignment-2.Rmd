---
title: "assignment 2"
author: "Study group 2"
date: "2023-03-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(pacman)

pacman::p_load(tidyverse,
        here,
        posterior,
        cmdstanr,
        brms, tidybayes, future, purrr, furrr)
```

# FUNCTIONS

```{r agent functions}

# Random bot
random_agent <- function(bias = 0.7) {
  choice <- rbinom(1,1, bias)
  return(choice)
}

# Win-shift-lose-stay agent
win_shift_agent <- function(prev_choice, feedback, bias_lose, bias_win) {
  if (feedback == 0) { #lose stay
    if(prev_choice == 0) { 
      choice = rbinom(1, 1, (1-bias_lose))}
    if(prev_choice == 1) { 
      choice = rbinom(1, 1, bias_lose)}
      }
  else if (feedback == 1) { #win shift
    if(prev_choice == 0) { 
      choice = rbinom(1, 1, bias_win)}
    if(prev_choice == 1) { 
      choice = rbinom(1, 1, (1-bias_win))}
  }
  return(choice)  
}
```


```{r simulation function RA}

sim_vs_random <- function(agents, trials, bias_lose, bias_win){
  
  feedback <- array(NA, c(agents, trials))
  performance_df <- data_frame()
  
  for (agent in 1:agents){
    self <- rep(NA, trials)
    bot <- rep(NA, trials)
  
    self[1] <- random_agent(0.5)
    
    for(trial in seq(trials)) {
      bot[trial] <- random_agent()
    }
    
    for (trial in 2:trials){
      if(self[trial-1] == bot[trial-1]) {
        feedback[agent, trial] = 1
      } 
      else {
        feedback[agent, trial] = 0
      }
      self[trial] <- win_shift_agent(prev_choice = self[trial-1], 
                                      feedback = feedback[agent, trial], 
                                      bias_lose = bias_lose, 
                                      bias_win = bias_win)
    }
    
    df_temp <- tibble(agent = agent, self, bot, trial = seq(trials), 
                      feedback = as.numeric(self==bot)) %>% 
      mutate(cumulative_self = cumsum(feedback)/seq_along(feedback),
             cumulative_bot = cumsum(1-feedback)/seq_along(feedback)) 
    
    performance_df <- rbind(performance_df, df_temp)
    
  }
  
  return(performance_df)
}
```


```{r simulation and fitting function}

sim_d_and_fit <- function(seed, trials, bias_win, bias_lose) {
  for (t in seq(trials)) {
    temp <-  sim_vs_random(agents = 1,
                           trials = trials, 
                           bias_lose = bias_lose,
                           bias_win = bias_win)
  }
  
  data <-  list(
    t = trials,
    choice = lead(temp$self, 1),
    self = temp$self,
    other = temp$bot
  )
  
  data$choice[t] <- 0

  samples <- model$sample(
    data = data,
    seed = seed,
    chains = 1,
    parallel_chains = 1,
    threads_per_chain = 1,
    iter_warmup = 1000,
    iter_sampling = 2000,
    refresh = 0,
    max_treedepth = 20,
    adapt_delta = 0.99,
  )

  draws_df <- as_draws_df(samples$draws())
  #temp <- tibble(bias_winEst = draws_df$bias_win_posterior, 
  #               bias_loseEst = draws_df$bias_lose_posterior, 
    #             bias_winTrue = bias_win, 
    #             bias_loseTrue = bias_lose
    #             )
  
  temp <- tibble(bias_winEst = draws_df$bias_win_posterior, 
                 bias_loseEst = draws_df$bias_lose_posterior, 
                 bias_winTrue = bias_win, 
                 bias_loseTrue = bias_lose,
                 bias_win_prior = draws_df$bias_win_prior,
                 bias_lose_prior = draws_df$bias_win_prior
                 )
  temp2 <- draws_df %>% select(prior_preds_LR,
                               prior_preds_LL, 
                               prior_preds_WR, 
                               prior_preds_WL, 
                               post_preds_LR, 
                               post_preds_LL,
                               post_preds_WR,
                               post_preds_WL)
  
  df <- cbind(temp, temp2)
  
  return(df)
}

```

# FITTING THE MODEL

```{r import model}
## Specify where the model is
file <- file.path("model1_h.stan")
model <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1")) 


```


```{r test fitting}
test <- sim_d_and_fit(seed = 1000, trials = 500, bias_win = 0.7, bias_lose = 0.9)
```

# Parameter recovery
```{r}
pacman::p_load(tidyr, patchwork)
plan(multisession, workers = 4)

bias_win = seq(0,1, by = .1)
bias_lose = seq(0,1,by = .1)

d <- crossing(bias_win, bias_lose)

temp <- tibble(unique(d)) %>% 
  mutate(seed = 1000, trials = 100) # is seed what gives me 2000 estimated values pr combination of true values?? 

temp <- temp %>% select(seed, trials, bias_win, bias_lose)

recovery_df_500 <- future_pmap_dfr(temp, sim_d_and_fit, .options = furrr_options(seed = TRUE))

write.csv(recovery_df_100, "recovery_df_100.csv", row.names = FALSE)
```


```{r}
p1 <- ggplot(recovery_df_100, aes(bias_winTrue, bias_winEst)) + 
  geom_point(alpha = 0.1) + 
  geom_smooth() +
  theme_classic() + 
  labs(subtitle = "Bias_win") + 
  geom_abline(
    slope = 1, 
    intercept = 0,
    color = "red") +
  coord_cartesian(ylim = c(0,1))
# + facet_wrap(.~bias_loseTrue) # not sure it makes sense to plot with a facetwrap 

p2 <- ggplot(recovery_df_100, aes(bias_loseTrue, bias_loseEst)) +
  geom_point(alpha = 0.1) + 
  geom_smooth() +
  theme_classic() + 
  labs(subtitle = "Bias_lose") +
  geom_abline(
    slope = 1, 
    intercept = 0,
    color = "red") + 
  coord_cartesian(ylim = c(0,1))

p3 <- p1 + labs(title = "Parameter recovery for 100 trials") +p2

p3
```

# Parameter recovery with conversion from log odds to probabilies 
```{r}
# converting log odds to probabilities the analogue way 
# inv.logit() from the "boot" package does exactly the same 
# pacman::p_load(boot)
# in stan code: inv_logit()

#recovery_df <- recovery_df %>% 
 # mutate(
  #  bias_winEst_prop = exp(bias_winEst)/(1+exp(bias_winEst)),
   # bias_loseEst_prop = exp(bias_loseEst)/(1+exp(bias_loseEst))
  #)
```

# plotting time!! win stay vs. random agent 
# posterior + priors 
```{r}
pacman::p_load(boot)
# bias win
ggplot(test) +
  geom_density(aes(bias_winEst), fill="blue", alpha=0.3) +
  geom_density(aes(inv.logit(bias_win_prior)), fill="red", alpha=0.3) +
  xlab("Rate") + # Tendency to choose 1 ??
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = "Bias win")+
  geom_vline(xintercept = .7) +
  coord_cartesian(xlim = c(0,1))

# bias lose
ggplot(test) +
  geom_density(aes(bias_loseEst), fill="blue", alpha=0.3) +
  geom_density(aes(inv.logit(bias_lose_prior)), fill="red", alpha=0.3) +
  xlab("Rate") +
  ylab("Posterior Density") +
  theme_classic() + 
  labs(title = "Bias lose") + 
  geom_vline(xintercept = .9) +
  coord_cartesian(xlim = c(0,1))

```
Remember, win-shift! not sure the above plot makes sense? given the bias should change given the choice.. i.e., pull in different directions.

```{r}
# prior and post predictions - when losing and choosing left/0

ggplot(test) + 
  geom_histogram(aes(prior_preds_LL), color="lightblue", fill="blue", alpha=0.3, bins=90) +
  geom_histogram(aes(post_preds_LL), color="darkblue", fill="blue", alpha=0.3, bins=90) +
  #geom_point(x = 0.7*100, y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 100 trials") +
  ylab("Density") +
  theme_classic() + 
  labs(title = "Prior and posterior predicted choices when the agent choses 0 and loses") + 
  coord_cartesian(xlim = c(0,500))
```
So, the agent loses and has a stronger tendency to stay a their choice when losing. So the posterior distribution is pulled towards 0, which was the choice where the agent lost. 

```{r} 

ggplot(test) + 
  geom_histogram(aes(prior_preds_LR), color="lightblue", fill="blue", alpha=0.3, bins=90) +
  geom_histogram(aes(post_preds_LR), color="darkblue", fill="blue", alpha=0.3, bins=90) +
  #geom_point(x = 0.9*100, y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Density") +
  theme_classic() + 
  labs(title = "Prior and posterior predicted choices when the agent choses 1 and loses") + 
  coord_cartesian(xlim = c(0,500))


```
But according to the above explanation this distribution should be pulled towards 1.... 

```{r}
# prior and post predictions - when winning

ggplot(test) + 
  geom_histogram(aes(prior_preds_WL), color="lightblue", fill="blue", alpha=0.3, bins=90) +
  geom_histogram(aes(post_preds_WL), color="darkblue", fill="blue", alpha=0.3, bins=90) +
 # geom_point(x = 0.7*100, y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Density") +
  theme_classic() + 
  labs(title = "Prior and posterior predicted choices when the agent choses 0 and wins") + 
  coord_cartesian(xlim = c(0,500))

```


```{r}

ggplot(test) + 
  geom_histogram(aes(prior_preds_WR), color="lightblue", fill="blue", alpha=0.3, bins=90) +
  geom_histogram(aes(post_preds_WR), color="darkblue", fill="blue", alpha=0.3, bins=90) +
#  geom_point(x = 0.7*100, y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Density") +
  theme_classic() + 
  labs(title = "Prior and posterior predicted choices when the agent choses 1 and wins") + 
  coord_cartesian(xlim = c(0,500))

```
```{r prior sensitivity check}
prior_mean_bias_win <- 0
prior_sd_bias_win <- seq(0.1, 0.5, 0.1)


prior_mean_bias_lose <- 0
prior_sd_bias_lose <- seq(0.1, 0.5, 0.1)


priors <-  tibble(expand.grid(tibble(prior_mean_bias_win, prior_sd_bias_win, prior_mean_bias_lose, prior_sd_bias_lose)))

## Specify where the model is
file2 <- file.path("model1_prior_sensitivity.stan")
model2 <- cmdstan_model(file2, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1")) 


```


```{r}
sim_d_and_fit_prior_sensitivity <- function(prior_mean_bias_win, prior_sd_bias_win, prior_mean_bias_lose, prior_sd_bias_lose) {
  
    for (t in seq(100)) {
    temp <-  sim_vs_random(agents = 1,
                           trials = 100, 
                           bias_lose = 0.9,
                           bias_win = 0.7)
  }
  
  data <-  list(
    t = 100,
    choice = lead(temp$self, 1),
    self = temp$self,
    other = temp$bot,
    prior_mean_bias_win = prior_mean_bias_win,
    prior_sd_bias_win = prior_sd_bias_win,
    prior_mean_bias_lose = prior_mean_bias_lose,
    prior_sd_bias_lose = prior_sd_bias_lose
  )
  
  data$choice[t] <- 0
  
    samples <- model2$sample(
      data = data,
      seed = 1000,
      chains = 1,
      parallel_chains = 1,
      threads_per_chain = 1,
      iter_warmup = 1000,
      iter_sampling = 2000,
      refresh = 0,
      max_treedepth = 20,
      adapt_delta = 0.99,
    )
    
    draws_df <- as_draws_df(samples$draws()) 
      temp <- tibble(bias_win_prior = draws_df$bias_win_prior, 
                     bias_lose_prior = draws_df$bias_lose_prior, 
                     bias_winEst = draws_df$bias_win_posterior, 
                     bias_loseEst = draws_df$bias_lose_posterior, 
                     prior_mean_bias_win = prior_mean_bias_win,
                     prior_sd_bias_win = prior_sd_bias_win, 
                     prior_mean_bias_lose = prior_mean_bias_lose,
                     prior_sd_bias_lose = prior_sd_bias_lose)
    
    return(temp)
  
}

```

```{r}

ps_recovery_df <- future_pmap_dfr(priors, sim_d_and_fit_prior_sensitivity, .options = furrr_options(seed = TRUE))

write_csv(ps_recovery_df, "m1PriorSensitivity.csv")
```

